{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7925b7",
   "metadata": {},
   "source": [
    "# ARCE experiments-03: adding $H_\\text{eff}$\n",
    "\n",
    "The most straigtforward setting, where both $h$ and $P(h)$ are observable.\n",
    "\n",
    "Add bias via putting some spurious correlation in the prompt (and change the name of the objects).\n",
    "Like \"Turn off the screen after experiment\". And change the name of the object at the same time.\n",
    "\n",
    "## 0. Prepare $h$ and $d^0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b431982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import permutations\n",
    "import os\n",
    "import openai\n",
    "import copy\n",
    "\n",
    "from utils.gpt_api import multi_turn_chatgpt\n",
    "from utils.text_logger import text_logger\n",
    "from utils.h_and_d import data_generator\n",
    "from utils.h_and_d import h_x, cnt_of_status, gen_hstar_rnd, gen_hstar_given_status\n",
    "from utils.standard_prompts import gen_hd_prompt, gen_dh_prompt, gen_data_prompt, gen_h_refine_prompt, gen_h_search_prompt\n",
    "# from utils.evaluations import eval_feedback_h, convert_chatcompl_to_json\n",
    "from utils.evaluations import *\n",
    "\n",
    "def rnd_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "H_INDEX = 132 #[6, 26, 27, 33, 77, 78, 83, 111, 128, 132]\n",
    "GLOBAL_TMP = 1 # [1, 0.5, 0.1]\n",
    "SEED = 42 # [10086, 14843, 42, 1314, 916, 1024]\n",
    "GEN = 4\n",
    "M_generate = 4   # How many example generated by agent for the next generation\n",
    "M_d0 = 8\n",
    "LOOK_BACK = 2\n",
    "\n",
    "INTERACTION = 'self'  # [self, hypothesis, none]\n",
    "BIAS_START = 'strong' # [strong, medium, weak, none]\n",
    "BIAS_END = 'none' # [strong, medium, weak, none]\n",
    "BIAS_NAME = 'start%s_end%s'%(BIAS_START, BIAS_END)\n",
    "MODEL_NAME =   \"mistral-small-2312\"  # [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\", \"claude-3-haiku-20240307\", \"mistral-tiny-2312\", \"mistral-small-2312\"]\n",
    "\n",
    "rnd_seed(SEED)\n",
    "\n",
    "hindex = \"h\"+str(H_INDEX).zfill(3)\n",
    "EXP_NAME = \"%s_%s_%s_seed%d\"%(INTERACTION, hindex, BIAS_NAME, SEED)\n",
    "EXP_PATH = './exp_logs_' + MODEL_NAME + '/add_interaction'\n",
    "exp_path = os.path.join(EXP_PATH, EXP_NAME)\n",
    "LOG = text_logger(file_name='chat_log', exp_path=exp_path, silence = True)\n",
    "LOG.write_to_file('This is an experiment trying to see the convergence of H(P(h))')\n",
    "# ------- Exp_name follows the section of h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cd8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTS = ['A', 'B', 'C', 'D', 'screen']\n",
    "STATES = [\"on\",\"off\",\"und\"]\n",
    "N = len(OBJECTS)\n",
    "# ------------- Generate h satisfying \n",
    "def generate_all_statuses(N,M, packed=False):\n",
    "    def generate_all_statuses_(N, M):\n",
    "        def generate_status_helper(current_status):\n",
    "            if len(current_status) == N:\n",
    "                all_statuses.append(current_status.copy())\n",
    "                return\n",
    "            for state in range(M):\n",
    "                current_status.append(STATES[state])\n",
    "                generate_status_helper(current_status)\n",
    "                current_status.pop()\n",
    "        all_statuses = []\n",
    "        generate_status_helper([])\n",
    "        return all_statuses\n",
    "    tmp_all_possible_statuses = generate_all_statuses_(N, M)\n",
    "    if packed:\n",
    "        all_possible_statuses = []\n",
    "        for s in tmp_all_possible_statuses:\n",
    "            all_possible_statuses.append(s[::-1])\n",
    "        return all_possible_statuses\n",
    "    else:\n",
    "        return tmp_all_possible_statuses\n",
    "    \n",
    "all_possible_statuses = generate_all_statuses(N=len(OBJECTS), M=len(STATES), packed=False)\n",
    "\n",
    "hcomp_df = pd.DataFrame(columns=['A','B','C','D','screen','status','n_on','n_off','n_und'])\n",
    "feasible_status = []\n",
    "index = 0\n",
    "for l in all_possible_statuses:\n",
    "    if l[-1]=='off':\n",
    "        pass\n",
    "    else:\n",
    "        feasible_status.append(l)\n",
    "        n_on, n_off, n_und = cnt_of_status(l)\n",
    "        hcomp_df.loc[index] = [l[0],l[1],l[2],l[3],l[4], [l[0],l[1],l[2],l[3],l[4]], n_on, n_off, n_und]\n",
    "        index += 1\n",
    "        \n",
    "#hcomp_df.sort_values(by=[\"n_on\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e392fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'und', 'B': 'off', 'C': 'off', 'D': 'on', 'screen': 'on'}\n",
      "{'A': 'und', 'B': 'off', 'C': 'off', 'D': 'on', 'screen': 'off'}\n"
     ]
    }
   ],
   "source": [
    "h_star = gen_hstar_given_status(hcomp_df.iloc[[H_INDEX]]['status'][H_INDEX], OBJECTS)\n",
    "h_bar = copy.deepcopy(h_star)\n",
    "h_bar['screen'] = 'off'\n",
    "\n",
    "print(h_star)\n",
    "print(h_bar)\n",
    "# --------- Get d0 given h_star\n",
    "D_GENERATOR = data_generator(h_star, N_test=0)\n",
    "d0 = D_GENERATOR.sample_d0_under_hbar(M=M_d0, h_bar=h_bar)\n",
    "\n",
    "LOG.write_to_file('In this experiment,h* is %s, h_bar is %s. Global temperature is %f\\n'%(h_star, h_bar, GLOBAL_TMP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d584035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71a50e",
   "metadata": {},
   "source": [
    "## 1. Run experiments with modified prompt and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59907bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m h_refine_prompt \u001b[38;5;241m=\u001b[39m gen_h_search_prompt(hd_feedback_str, d0_str, rule_format)\n\u001b[0;32m     68\u001b[0m gpt_feedback, _ , cnt_tokens \u001b[38;5;241m=\u001b[39m GPT_AGENT\u001b[38;5;241m.\u001b[39mcall_chatgpt(h_refine_prompt, lookback_round\u001b[38;5;241m=\u001b[39mLOOK_BACK, update_hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt_feedback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRule\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tmp\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     71\u001b[0m     hd_refi_fb_str \u001b[38;5;241m=\u001b[39m tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRule\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\icl\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\.conda\\envs\\icl\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\.conda\\envs\\icl\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "if BIAS_START == 'strong':\n",
    "    spu_corr1 = \"Turn off the screen after the experiment.\"\n",
    "elif BIAS_START == 'medium':\n",
    "    spu_corr1 = \"John will turn off the screen after the experiment.\"\n",
    "elif BIAS_START == 'weak':\n",
    "    spu_corr1 = \"John will close the screen after the experiment.\"\n",
    "else:\n",
    "    spu_corr1 = \"\"\n",
    "\n",
    "if BIAS_END == 'strong':\n",
    "    spu_corr2 = \"\\nTurn off the screen after the experiment.\"\n",
    "elif BIAS_END == 'medium':\n",
    "    spu_corr2 = \"\\nJohn will turn off the screen after the experiment.\"\n",
    "elif BIAS_END == 'weak':\n",
    "    spu_corr2 = \"\\nJohn will close the screen after the experiment.\"\n",
    "else:\n",
    "    spu_corr2 = \"\"\n",
    "\n",
    "# ========== In this game_prompt, we add one scentence before d0\n",
    "# spu_corr1 = \"Turn off the screen after the experiment.\"\n",
    "# #\"John will turn off the screen after the experiment.\"#\"Turn off the screen of the monitor.\"#\"Turn off the screen after the experiment.\"\n",
    "\n",
    "game_prompt = 'Let us play a rule following game. You need to generate a rule that maps the following inputs to their corresponding outputs, or generate examples following a given rule. Each example is an input-output pair. The input is a list of objects. If any objects with status on in the input, the output should be on. If all objects in the input are off, the output is off. If only objects with off and und in the list, the output should be undetermined (und for short). The output is either \"on\", \"off\", or \"und\", indicating the state of the light. For each object, determine whether it triggers the light to turn on, does not trigger it, or if it is undetermined. We only have %d objects in this game: %s. %s\\n'%(N, OBJECTS, spu_corr1)\n",
    "LOG.msg_to_gpt(game_prompt)\n",
    "GPT_AGENT = multi_turn_chatgpt(model=MODEL_NAME, temperature=GLOBAL_TMP, top_p=1, logger=LOG, game_description=game_prompt)\n",
    "\n",
    "# ------------ Step 1: random choose M training data samples as d0\n",
    "# spu_corr2 = \"\"#\"\\nTurn off the screen after the experiment.\"#\"\\nClose the screen after experiment.\"#\"\\nTurn off the screen after the experiment.\"#\n",
    "if MODEL_NAME.startswith('claude'):\n",
    "    rule_format = 'Rule: {\"object 1\": <\"on\"/\"off\"/\"und\">, \"object 2\": <\"on\"/\"off\"/\"und\">, ...}%s\\nWe only have five objects, they are [\"A\", \"B\", \"C\", \"D\", \"screen\"].'%spu_corr2\n",
    "elif MODEL_NAME.startswith('mistral'):\n",
    "    rule_format = 'Rule: {\"object 1\": <\"on\"/\"off\"/\"und\">, \"object 2\": <\"on\"/\"off\"/\"und\">, ...}%s.'%spu_corr2\n",
    "else:\n",
    "    rule_format = 'Rule: {\"object 1\": <\"on\"/\"off\"/\"und\">, \"object 2\": <\"on\"/\"off\"/\"und\">, ...}%s'%spu_corr2\n",
    "#rule_format = 'Rule: {object 1 on/off/und; object 2 on/off/und; ...}'\n",
    "\n",
    "data_str = gen_data_prompt(d0, need_stat=True)\n",
    "d0_str = data_str\n",
    "results = {'nh_corr':[],'nh_perf':[],'d_sampled':[],'prompt_token':[],'rules':[],'rules_refine':[]}\n",
    "results['d_sampled'].append(data_str)\n",
    "results['rules'].append(h_star)\n",
    "\n",
    "results_prob_list = []\n",
    "for g in tqdm(range(GEN)):\n",
    "    LOG.write_to_file('----------- Gen %d -----------'%g)\n",
    "    # ------------ Step 2: h~P(h|d)\n",
    "    hd_prompt = gen_hd_prompt(data=data_str, ask_rule=rule_format)\n",
    "        # --------- Get feedback\n",
    "    hd_feedback, hd_fb_probs, cnt_tokens = GPT_AGENT.call_chatgpt(hd_prompt, fake_response=None, \n",
    "                                              logprobs=True, top_logprobs=5, lookback_round=LOOK_BACK)\n",
    "    results['rules'].append(hd_feedback)\n",
    "    results_prob_list.append(hd_fb_probs)\n",
    "    results['prompt_token'].append(cnt_tokens)\n",
    "\n",
    "    try:\n",
    "        hd_feedback_str = json.loads(hd_feedback.split(\"Rule: \")[-1])\n",
    "    except:\n",
    "        hd_feedback_str = json.loads(hd_feedback.split(\"Rule: \")[-1].split('\\n')[0])\n",
    "    \n",
    "    nh_corr, nh_perf = eval_feedback_h(h=h_star, fb_h=hd_feedback_str, N=N)\n",
    "    results['nh_corr'].append(nh_corr/N)\n",
    "    results['nh_perf'].append(nh_perf)\n",
    "    \n",
    "        # ------------ Step 2.5: refine the hypothesis\n",
    "    \n",
    "    if INTERACTION.lower() == \"self\":\n",
    "        h_refine_prompt = gen_h_search_prompt(hd_feedback_str, d0_str, rule_format)\n",
    "        gpt_feedback, _ , cnt_tokens = GPT_AGENT.call_chatgpt(h_refine_prompt, lookback_round=LOOK_BACK, update_hist=False)\n",
    "        tmp = json.loads(gpt_feedback)\n",
    "        if 'Rule' in tmp.keys():\n",
    "            hd_refi_fb_str = tmp['Rule']\n",
    "        else:\n",
    "            hd_refi_fb_str = tmp['rule']\n",
    "        results['rules_refine'].append(hd_refi_fb_str)\n",
    "    elif INTERACTION.lower() == \"hypothesis\":\n",
    "        h_refine_prompt, refine_flag = gen_h_refine_prompt(hd_feedback_str, d0_str, rule_format)\n",
    "        hrefine_feedback, _ , cnt_tokens = GPT_AGENT.call_chatgpt(h_refine_prompt, lookback_round=LOOK_BACK, update_hist=False)\n",
    "        if refine_flag:     # --- h is not perfect correct, trigger refine\n",
    "            hd_refi_fb_str = hrefine_feedback.split('Rule: ')[1]\n",
    "            results['rules_refine'].append(hd_refi_fb_str)\n",
    "        else:\n",
    "            hd_refi_fb_str = hd_feedback_str\n",
    "            results['rules_refine'].append(hd_feedback_str) \n",
    "    else:\n",
    "        hd_refi_fb_str = hd_feedback_str\n",
    "        results['rules_refine'].append(hd_feedback_str) \n",
    "    \n",
    "    results['prompt_token'].append(cnt_tokens)\n",
    "    if g<GEN-1:\n",
    "        # ------------ Step 3: d~P(d|h)\n",
    "        dh_prompt = gen_dh_prompt(M = M_generate, rule = hd_refi_fb_str)\n",
    "            # --------- Get feedback\n",
    "        dh_feedback, _, cnt_tokens = GPT_AGENT.call_chatgpt(dh_prompt, fake_response=None, lookback_round=LOOK_BACK)\n",
    "        results['prompt_token'].append(cnt_tokens)\n",
    "        results['d_sampled'].append(dh_feedback)\n",
    "        # ----------- Step 4: data_str <-- dh_feedback\n",
    "        data_str = dh_feedback\n",
    "    #time.sleep(30)\n",
    "print(results['nh_corr'])\n",
    "print(results['prompt_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Save prob_lists\n",
    "if MODEL_NAME.startswith('gpt'):\n",
    "    file_name = 'prob_list_all.json'\n",
    "    save_path = os.path.join(exp_path, file_name)    \n",
    "    json.dump(convert_chatcompl_to_json(results_prob_list), open(save_path, 'w' ))    \n",
    "\n",
    "file_name2 = 'other_results_all.json'\n",
    "save_path2 = os.path.join(exp_path, file_name2)\n",
    "json.dump(results, open(save_path2, 'w' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('======= Before refine ========')\n",
    "# for i in range(GEN+1):\n",
    "#     if i==0:\n",
    "#         print('Rul*: ',end='')\n",
    "#     print(results['rules'][i])\n",
    "    \n",
    "# print('======= After refine ========')\n",
    "# print('*%s'%results['rules'][0])\n",
    "# for i in range(GEN):\n",
    "#     print(' %s'%results['rules_refine'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da88247",
   "metadata": {},
   "source": [
    "## Calculate necessary quantities\n",
    "\n",
    "Given other_results_all.json, calculate:\n",
    "\n",
    "1. Number of correct prediction in $d^0$ for each gen\n",
    "2. Number of screen:off for each gen\n",
    "3. Whether $h^{T*}=h^t$ for each gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c85ee-4208-4196-8c10-e2668f5306f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dstr_to_pairs(d_str):\n",
    "    tmp_str = d_str.split('\\n')\n",
    "    while \"\" in tmp_str:\n",
    "        tmp_str.remove(\"\")\n",
    "    data_pairs = []\n",
    "    for s in range(int(len(tmp_str)*0.5)):\n",
    "        tmp_input = tmp_str[2*s].split(': ')[1].split(', ')\n",
    "        tmp_output = tmp_str[2*s+1].split(': ')[1]\n",
    "        data_pairs.append((tmp_input, tmp_output))\n",
    "    return data_pairs\n",
    "\n",
    "def count_corr_d0_pairs(d_pairs, rule):\n",
    "    corr_cnt, all_cnt = 0, 0\n",
    "    for x,y in d_pairs:\n",
    "        all_cnt += 1\n",
    "        if h_x(x, rule)==y:\n",
    "            corr_cnt += 1\n",
    "    return corr_cnt, all_cnt\n",
    "\n",
    "def eval_get_corr_h(results_read):\n",
    "    h_corr_list = []\n",
    "    h_star_read = results_read['rules'][0]\n",
    "    for i in range(GEN-1):\n",
    "        dt_str = results_read['d_sampled'][i+1].split('\\n')\n",
    "        while \"\" in dt_str:\n",
    "            dt_str.remove(\"\")\n",
    "        dt_pairs = dlist_to_pairs(dt_str)\n",
    "        corr_cnt, _ = count_corr_d0_pairs(dt_pairs, h_star_read)\n",
    "        h_corr_list.append(corr_cnt)\n",
    "    return h_corr_list\n",
    "\n",
    "def cal_screen_off_hbar(rule_list, h_bar):\n",
    "    cnt_screen, cnt_h = 0, 0\n",
    "    for r in rule_list:\n",
    "        if r['screen']=='off':\n",
    "            cnt_screen += 1\n",
    "        if r==h_bar:\n",
    "            cnt_h += 1\n",
    "    return cnt_screen, cnt_h, len(rule_list)\n",
    "\n",
    "def updata_stats(stats, results_read,):\n",
    "    d0_str = results_read['d_sampled'][0]   # Get d0 from the log\n",
    "    d0_corr_list = eval_get_corr_d0(d0_str, results_read)  # How many d0 each ht can correctly predict\n",
    "    h_bar = results_read['rules'][0]\n",
    "    h_bar['screen']='off'\n",
    "    cnt_screen_start, cnt_h, all_cnt = cal_screen_off_hbar(results_read['rules_refine'][:0], h_bar)\n",
    "    cnt_screen, cnt_h, all_cnt = cal_screen_off_hbar(results_read['rules_refine'][-AVG_BACK:], h_bar)\n",
    "    cnt_corr_d0 = np.sum(d0_corr_list[-AVG_BACK:])\n",
    "    all_cnt_corr_d0 = AVG_BACK*8\n",
    "    stats[\"cnt_screen_start\"].append(cnt_screen_start)\n",
    "    stats[\"cnt_screen_end\"].append(cnt_screen)\n",
    "    stats[\"cnt_h\"].append(cnt_h)\n",
    "    stats[\"cnt_all\"].append(all_cnt)\n",
    "    stats[\"cnt_d0\"].append(cnt_corr_d0)\n",
    "    stats[\"cnt_d0_all\"].append(all_cnt_corr_d0)\n",
    "\n",
    "def regularize_results(results_read):    \n",
    "    for i in range(len(results_read['rules'])):\n",
    "        if type(results_read['rules'][i]) != dict:\n",
    "            results_read['rules'][i] = json.loads(results_read['rules'][i].split(\"Rule: \")[1])\n",
    "\n",
    "    for i in range(len(results_read['rules_refine'])):\n",
    "        if type(results_read['rules_refine'][i]) != dict:\n",
    "            results_read['rules_refine'][i] = json.loads(results_read['rules_refine'][i])  \n",
    "    return results_read\n",
    "\n",
    "def get_results_read(exp_path_load):\n",
    "    #save_path = os.path.join(exp_path_load, 'prob_list_all.json') \n",
    "    save_path2 = os.path.join(exp_path_load, 'other_results_all.json')\n",
    "    #prob_list_read = json.load( open( save_path ))\n",
    "    results_read = json.load(open(save_path2))\n",
    "    return results_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a399a-e70c-4feb-a7de-2c2842fab3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_path = \"E://P5_iICL//iterated_learning_exp//exp_logs_gpt-3.5-turbo-0125//add_interaction//hypothesis_h033_startnone_endnone_seed42\"\n",
    "if MODEL_NAME.startswith('gpt'):\n",
    "    save_path = os.path.join(exp_path, 'prob_list_all.json')\n",
    "    prob_list_read = json.load( open( save_path ))\n",
    "    \n",
    "save_path2 = os.path.join(exp_path, 'other_results_all.json')\n",
    "results_read = json.load(open(save_path2))\n",
    "results_read = regularize_results(results_read)\n",
    "GEN = len(results_read['nh_corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb57fd5-73a7-420b-8dab-d160075c4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- How many correct d0 each ht can predict\n",
    "d0_str = results_read['d_sampled'][0]   # Get d0 from the log\n",
    "d0_corr_list = eval_get_corr_d0(d0_str, results_read)  # How many d0 each ht can correctly predict\n",
    "\n",
    "# ----------- How many screen:off in each ht\n",
    "ht_screenoff_list = []\n",
    "\n",
    "# ----------- How many ht == h*\n",
    "h_tgt = results_read['rules'][0]\n",
    "h_tgt['screen'] = 'off'\n",
    "ht_tgt_list = []\n",
    "\n",
    "for i in range(len(results_read['rules_refine'])):\n",
    "    tmp_screenoff = int(results_read['rules_refine'][i]['screen']=='off')\n",
    "    ht_screenoff_list.append(tmp_screenoff)\n",
    "    #ht_tgt_list.append(int(results_read['rules_refine'][i]==h_tgt))\n",
    "    ht_tgt_list.append(int(tmp_screenoff==1 and d0_corr_list[i]==8))\n",
    "\n",
    "print(\"----------- How many correct d0 each ht can predict\")\n",
    "print(d0_corr_list)\n",
    "print(\"----------- How many screen:off in each ht\")\n",
    "print(ht_screenoff_list)\n",
    "# print(\"----------- How many ht == h*\")\n",
    "print(ht_tgt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380945a-6bad-4733-bd0d-c1c238981762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f73df9-bfc1-4d5d-b862-11bfdaf17473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8485d97-d0f5-4e14-b083-6ae150d407bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d4cb0-4618-4e3c-abac-e1bc4433143d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9835f3-fd87-4ae9-bf44-e9e718cc4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c136b-5ff8-41c9-b528-dc2bbd3c685a",
   "metadata": {},
   "source": [
    "## Visualize results (backup) don't delete, the reporting code is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Assign number of correct predictions to each h\n",
    "\n",
    "\n",
    "def dlist_to_pairs(d_list):\n",
    "    data_pairs = []\n",
    "    if not (d_list[0].startswith('Input') or d_list[0].startswith('Output')):\n",
    "        d_list = d_list[1:]\n",
    "    for i in range(int(0.5*len(d_list))):\n",
    "        tmp_input = d_list[2*i].split(': ')[1].split(', ')\n",
    "        tmp_output = d_list[2*i+1].split(': ')[1]\n",
    "        data_pairs.append((tmp_input, tmp_output))\n",
    "    return data_pairs\n",
    "\n",
    "def count_corr_d0_pairs(d_pairs, rule):\n",
    "    corr_cnt, all_cnt = 0, 0\n",
    "    for x,y in d_pairs:\n",
    "        all_cnt += 1\n",
    "        if h_x(x, rule)==y:\n",
    "            corr_cnt += 1\n",
    "    return corr_cnt, all_cnt\n",
    "\n",
    "def count_corr_d0(d, h):\n",
    "    # Calculate how many examples in d can be explained by given h\n",
    "    corr_cnt = 0\n",
    "    for _, row in d.iterrows():\n",
    "        x, y = row['obj'], row['stat']\n",
    "        y_pred = h_x(x, h)\n",
    "        if y==y_pred:\n",
    "            corr_cnt += 1\n",
    "    return corr_cnt\n",
    "\n",
    "def cal_entropy(hd_fb_probs):\n",
    "    token_logprob = extract_probs(hd_fb_probs, OBJECTS, top_n=5)\n",
    "    entropy = 0\n",
    "    for i in range(len(all_possible_statuses)):\n",
    "        h_tmp = {}\n",
    "        for j in range(len(OBJECTS)):\n",
    "            h_tmp[OBJECTS[j]] = all_possible_statuses[i][j]\n",
    "        if h_tmp == h_star:\n",
    "            h_star_idx = i\n",
    "        obj_logprob, obj_prob = cal_prob_of_h(h_tmp, token_logprob)\n",
    "        entropy += -obj_prob*obj_logprob\n",
    "    return entropy\n",
    "\n",
    "# ============= Assign number of correct predictions to each h\n",
    "def count_corr_d0(d, h):\n",
    "    # Calculate how many examples in d can be explained by given h\n",
    "    corr_cnt = 0\n",
    "    for _, row in d.iterrows():\n",
    "        x, y = row['obj'], row['stat']\n",
    "        y_pred = h_x(x, h)\n",
    "        if y==y_pred:\n",
    "            corr_cnt += 1\n",
    "    return corr_cnt\n",
    "\n",
    "def cal_entropy(hd_fb_probs):\n",
    "    token_logprob = extract_probs(hd_fb_probs, OBJECTS, top_n=5)\n",
    "    entropy = 0\n",
    "    for i in range(len(all_possible_statuses)):\n",
    "        h_tmp = {}\n",
    "        for j in range(len(OBJECTS)):\n",
    "            h_tmp[OBJECTS[j]] = all_possible_statuses[i][j]\n",
    "        if h_tmp == h_star:\n",
    "            h_star_idx = i\n",
    "        obj_logprob, obj_prob = cal_prob_of_h(h_tmp, token_logprob)\n",
    "        entropy += -obj_prob*obj_logprob\n",
    "    return entropy\n",
    "\n",
    "def draw_pic(hd_fb_probs, ax=None, y_log=True, ylim=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1,figsize=(15,5))\n",
    "    token_logprob = extract_probs(hd_fb_probs, OBJECTS, top_n=5)\n",
    "\n",
    "    prob_list, corr_list = [], []\n",
    "    for i in range(len(all_possible_statuses)):\n",
    "        h_tmp = {}\n",
    "        for j in range(len(OBJECTS)):\n",
    "            h_tmp[OBJECTS[j]] = all_possible_statuses[i][j]\n",
    "        if h_tmp == h_star:\n",
    "            h_star_idx = i\n",
    "        obj_logprob, obj_prob = cal_prob_of_h(h_tmp, token_logprob)\n",
    "        prob_list.append(obj_prob)\n",
    "        corr_cnt = count_corr_d0(d0, h_tmp)\n",
    "        corr_list.append(corr_cnt)\n",
    "    prob_list = np.array(prob_list)\n",
    "    corr_list = np.array(corr_list)\n",
    "\n",
    "    ALPHA_LIST = [0.05, 0.2, 0.3, 0.5, 1]\n",
    "    x_axis = np.arange(0,243)\n",
    "\n",
    "    for i in range(N):\n",
    "        mask = corr_list==i\n",
    "        ax.bar(x_axis[mask],prob_list[mask],width=1, color='royalblue',alpha=ALPHA_LIST[i],label='h(d0)='+str(i))\n",
    "    if y_log:\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_xlim(-3, 245)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    ax.plot((h_star_idx), (prob_list[h_star_idx]), color='red',alpha=1,linestyle=' ',marker='*',markersize=10, label='h*')\n",
    "    ax.legend(fontsize=16, ncol=2)\n",
    "\n",
    "def get_all_prob_lists(prob_list_read):\n",
    "    off_prob_list = []\n",
    "    on_prob_list = []\n",
    "    und_prob_list = []\n",
    "    for g in range(GEN):\n",
    "        off_flg, on_flg, und_flg = False, False, False\n",
    "        for i in range(5):\n",
    "            if prob_list_read[g][-2]['top_logprobs'][i]['token']=='off':\n",
    "                off_flg = True\n",
    "                off_prob_list.append(np.exp(prob_list_read[g][-2]['top_logprobs'][i]['logprob']))\n",
    "            elif prob_list_read[g][-2]['top_logprobs'][i]['token']=='on':\n",
    "                on_flg = True\n",
    "                on_prob_list.append(np.exp(prob_list_read[g][-2]['top_logprobs'][i]['logprob']))\n",
    "            elif prob_list_read[g][-2]['top_logprobs'][i]['token']=='und':\n",
    "                und_flg = True\n",
    "                und_prob_list.append(np.exp(prob_list_read[g][-2]['top_logprobs'][i]['logprob']))\n",
    "        if not off_flg:\n",
    "            off_prob_list.append(0)\n",
    "        if not on_flg:\n",
    "            on_prob_list.append(0)\n",
    "        if not und_flg:\n",
    "            und_prob_list.append(0)\n",
    "    return off_prob_list, on_prob_list, und_prob_list\n",
    "\n",
    "# ============= Code for generate P(h) ===============\n",
    "def extract_probs(gpt_fb, objects, top_n=5):\n",
    "    token_logprob = {}\n",
    "    for i in range(len(gpt_fb)):\n",
    "        if gpt_fb[i]['token'] in objects:\n",
    "            obj = gpt_fb[i]['token']\n",
    "            obj_toplogs = gpt_fb[i+3]['top_logprobs']\n",
    "            token_logprob[obj]={}\n",
    "            for j in range(top_n):\n",
    "                candi_token = obj_toplogs[j]['token']\n",
    "                candi_prob = obj_toplogs[j]['logprob']\n",
    "                token_logprob[obj][candi_token] = candi_prob #np.exp(candi_prob)\n",
    "    return token_logprob\n",
    "\n",
    "def cal_prob_of_h(h_star, token_logprob):\n",
    "    obj_logprob = 0\n",
    "    for obj in h_star.keys():\n",
    "        status = h_star[obj]\n",
    "        if status in token_logprob[obj].keys():\n",
    "            tmp_logprob = token_logprob[obj][status]\n",
    "        else:\n",
    "            tmp_logprob = -10\n",
    "        obj_logprob += tmp_logprob\n",
    "    return obj_logprob, np.exp(obj_logprob)\n",
    "\n",
    "def generate_all_statuses(N, M):\n",
    "    def generate_status_helper(current_status):\n",
    "        if len(current_status) == N:\n",
    "            all_statuses.append(current_status.copy())\n",
    "            return\n",
    "\n",
    "        for state in range(M):\n",
    "            current_status.append(STATES[state])\n",
    "            generate_status_helper(current_status)\n",
    "            current_status.pop()\n",
    "\n",
    "    all_statuses = []\n",
    "    generate_status_helper([])\n",
    "\n",
    "    return all_statuses\n",
    "\n",
    "# Example usage:\n",
    "N = len(OBJECTS)  # Number of variables\n",
    "M = len(STATES)  # Number of possible states for each variable\n",
    "\n",
    "all_possible_statuses = generate_all_statuses(N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ad74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('======= Before refine ========')\n",
    "for i in range(GEN+1):\n",
    "    if i==0:\n",
    "        print('Rul*: ',end='')\n",
    "    print(results_read['rules'][i])\n",
    "    \n",
    "print('======= After refine ========')\n",
    "print('*%s'%results_read['rules'][0])\n",
    "for i in range(GEN):\n",
    "    print(' %s'%results_read['rules_refine'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697cf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c11875-8db1-4ae0-a118-be4aaff7c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_prob_list, on_prob_list, und_prob_list = get_all_prob_lists(prob_list_read)\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,4))\n",
    "x_axis=np.arange(0,GEN+1)\n",
    "ax[0].plot(x_axis, [0.33]+off_prob_list,label='off')\n",
    "ax[0].plot(x_axis, [0.33]+on_prob_list,label='on')\n",
    "ax[0].plot(x_axis, [0.33]+und_prob_list,label='und')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('P(Screen:?)')\n",
    "uni_entropy, oht_entropy = 0, 0\n",
    "for i in range(243):\n",
    "    if i==3:\n",
    "        prob = 1-242*1e-10\n",
    "        oht_entropy += -prob*np.log(prob)\n",
    "    uni_entropy += -(1/243)*np.log(1/243)\n",
    "    oht_entropy += -1e-10*np.log(1e-10)\n",
    "\n",
    "entropy_list = []\n",
    "for i in range(GEN):\n",
    "    entropy = cal_entropy(prob_list_read[i])\n",
    "    entropy_list.append(entropy)\n",
    "    \n",
    "ax[1].plot(entropy_list,label='GPT return')\n",
    "ax[1].plot([0,GEN-1],[uni_entropy,uni_entropy], label='Uniform')\n",
    "ax[1].plot([0,GEN-1],[oht_entropy,oht_entropy], label='One-hot')\n",
    "ax[1].legend(fontsize=16)\n",
    "ax[1].set_title('Entropy')\n",
    "\n",
    "d0_corr_list = eval_get_corr_d0(d0_str, results_read)\n",
    "h_corr_list = eval_get_corr_h(results_read)\n",
    "ax[2].plot(d0_corr_list, label='ht_corr_in_d0')\n",
    "ax[2].plot(h_corr_list, label='dt_corr_in_h*')\n",
    "ax[2].legend(fontsize=16)\n",
    "ax[2].set_title('h/d count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd736a-8fda-4932-9bd9-79429b75385e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffab5c-f3f7-40c3-a2cb-0a47c19be07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ed08d-829c-4472-a091-cfe85242422c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6572488-2a0d-48b8-b032-a0678f43f296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2f8af-7b3d-499d-9851-6e47eec67ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_screen_off_hbar(rule_list, h_bar):\n",
    "    cnt_screen, cnt_h = 0, 0\n",
    "    for r in rule_list:\n",
    "        if r['screen']=='off':\n",
    "            cnt_screen += 1\n",
    "        if r==h_bar:\n",
    "            cnt_h += 1\n",
    "    return cnt_screen, cnt_h, len(rule_list)\n",
    "\n",
    "def updata_stats(stats, results_read,):\n",
    "    d0_str = results_read['d_sampled'][0]\n",
    "    d0_corr_list = eval_get_corr_d0(d0_str, results_read)\n",
    "    h_bar = results_read['rules'][0]\n",
    "    h_bar['screen']='off'\n",
    "    cnt_screen_start, cnt_h, all_cnt = cal_screen_off_hbar(results_read['rules_refine'][:0], h_bar)\n",
    "    cnt_screen, cnt_h, all_cnt = cal_screen_off_hbar(results_read['rules_refine'][-AVG_BACK:], h_bar)\n",
    "    cnt_corr_d0 = np.sum(d0_corr_list[-AVG_BACK:])\n",
    "    all_cnt_corr_d0 = AVG_BACK*8\n",
    "    stats[\"cnt_screen_start\"].append(cnt_screen_start)\n",
    "    stats[\"cnt_screen_end\"].append(cnt_screen)\n",
    "    stats[\"cnt_h\"].append(cnt_h)\n",
    "    stats[\"cnt_all\"].append(all_cnt)\n",
    "    stats[\"cnt_d0\"].append(cnt_corr_d0)\n",
    "    stats[\"cnt_d0_all\"].append(all_cnt_corr_d0)\n",
    "\n",
    "def regularize_results(results_read):    \n",
    "    for i in range(len(results_read['rules'])):\n",
    "        if type(results_read['rules'][i]) != dict:\n",
    "            results_read['rules'][i] = json.loads(results_read['rules'][i].split(\"Rule: \")[1])\n",
    "\n",
    "    for i in range(len(results_read['rules_refine'])):\n",
    "        if type(results_read['rules_refine'][i]) != dict:\n",
    "            results_read['rules_refine'][i] = json.loads(results_read['rules_refine'][i])  \n",
    "    return results_read\n",
    "\n",
    "def get_results_read(exp_path_load):\n",
    "    #save_path = os.path.join(exp_path_load, 'prob_list_all.json') \n",
    "    save_path2 = os.path.join(exp_path_load, 'other_results_all.json')\n",
    "    #prob_list_read = json.load( open( save_path ))\n",
    "    results_read = json.load(open(save_path2))\n",
    "    return results_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517612e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AVG_BACK = 1\n",
    "GEN = 6\n",
    "stats_none = {\"cnt_screen_start\":[],\"cnt_screen_end\":[],\"cnt_h\":[],\"cnt_all\":[],\"cnt_d0\":[],\"cnt_d0_all\":[]}\n",
    "stats_self = {\"cnt_screen_start\":[],\"cnt_screen_end\":[],\"cnt_h\":[],\"cnt_all\":[],\"cnt_d0\":[],\"cnt_d0_all\":[]}\n",
    "stats_hypo = {\"cnt_screen_start\":[],\"cnt_screen_end\":[],\"cnt_h\":[],\"cnt_all\":[],\"cnt_d0\":[],\"cnt_d0_all\":[]}\n",
    "\n",
    "#allpath = os.walk(\"E://P5_iICL//iterated_learning_exp//exp_logs//add_interaction\")\n",
    "allpath = os.walk(\"E://P5_iICL//iterated_learning_exp//exp_logs_gpt-3.5-turbo-0125//add_interaction\")\n",
    "for path, dir_list, file_list in allpath:\n",
    "    for dir_name in dir_list:\n",
    "        results_read = get_results_read(os.path.join(path, dir_name))\n",
    "        results_read = regularize_results(results_read)\n",
    "        if dir_name.startswith('none'): \n",
    "            updata_stats(stats_none, results_read)\n",
    "        elif dir_name.startswith('self'):\n",
    "            updata_stats(stats_self, results_read)\n",
    "        elif dir_name.startswith('hypothesis'):\n",
    "            updata_stats(stats_hypo, results_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_KEY = 'cnt_d0'\n",
    "print('======= %s ======'%OBS_KEY)\n",
    "print(np.mean(stats_none[OBS_KEY]), np.var(stats_none[OBS_KEY]))\n",
    "print(np.mean(stats_self[OBS_KEY]), np.var(stats_self[OBS_KEY]))\n",
    "print(np.mean(stats_hypo[OBS_KEY]), np.var(stats_hypo[OBS_KEY]))\n",
    "\n",
    "OBS_KEY = 'cnt_screen_start'\n",
    "print('======= %s ======'%OBS_KEY)\n",
    "print(np.mean(stats_none[OBS_KEY]), np.var(stats_none[OBS_KEY]))\n",
    "print(np.mean(stats_self[OBS_KEY]), np.var(stats_self[OBS_KEY]))\n",
    "print(np.mean(stats_hypo[OBS_KEY]), np.var(stats_hypo[OBS_KEY]))\n",
    "\n",
    "OBS_KEY = 'cnt_screen_end'\n",
    "print('======= %s ======'%OBS_KEY)\n",
    "print(np.mean(stats_none[OBS_KEY]), np.var(stats_none[OBS_KEY]))\n",
    "print(np.mean(stats_self[OBS_KEY]), np.var(stats_self[OBS_KEY]))\n",
    "print(np.mean(stats_hypo[OBS_KEY]), np.var(stats_hypo[OBS_KEY]))\n",
    "\n",
    "OBS_KEY = 'cnt_h'\n",
    "print('======= %s ======'%OBS_KEY)\n",
    "print(np.mean(stats_none[OBS_KEY]), np.var(stats_none[OBS_KEY]))\n",
    "print(np.mean(stats_self[OBS_KEY]), np.var(stats_self[OBS_KEY]))\n",
    "print(np.mean(stats_hypo[OBS_KEY]), np.var(stats_hypo[OBS_KEY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba107a34-9aca-48b8-a3d6-4a577c6e9c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d458a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============= Code for generate P(h) ===============\n",
    "# def extract_probs(gpt_fb, objects, top_n=5):\n",
    "#     token_logprob = {}\n",
    "#     for i in range(len(gpt_fb)):\n",
    "#         if gpt_fb[i]['token'] in objects:\n",
    "#             obj = gpt_fb[i]['token']\n",
    "#             obj_toplogs = gpt_fb[i+3]['top_logprobs']\n",
    "#             token_logprob[obj]={}\n",
    "#             for j in range(top_n):\n",
    "#                 candi_token = obj_toplogs[j]['token']\n",
    "#                 candi_prob = obj_toplogs[j]['logprob']\n",
    "#                 token_logprob[obj][candi_token] = candi_prob #np.exp(candi_prob)\n",
    "#     return token_logprob\n",
    "\n",
    "# def cal_prob_of_h(h_star, token_logprob):\n",
    "#     obj_logprob = 0\n",
    "#     for obj in h_star.keys():\n",
    "#         status = h_star[obj]\n",
    "#         if status in token_logprob[obj].keys():\n",
    "#             tmp_logprob = token_logprob[obj][status]\n",
    "#         else:\n",
    "#             tmp_logprob = -10\n",
    "#         obj_logprob += tmp_logprob\n",
    "#     return obj_logprob, np.exp(obj_logprob)\n",
    "\n",
    "# def draw_pic(hd_fb_probs, h_star, d0_str, ax=None, y_log=True, ylim=None, legend=True, x_tickle=True, xlabel=None, star=True, color_type='screen'):\n",
    "#     h_bar = copy.deepcopy(h_star)\n",
    "#     h_bar['screen']='off'\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(1,1,figsize=(15,5))\n",
    "#     token_logprob = extract_probs(hd_fb_probs, OBJECTS, top_n=5)\n",
    "\n",
    "#     prob_list, corr_list, screen_list = [], [], []\n",
    "#     for i in range(len(all_possible_statuses)):\n",
    "#         h_tmp = {}\n",
    "#         for j in range(len(OBJECTS)):\n",
    "#             h_tmp[OBJECTS[j]] = all_possible_statuses[i][j]\n",
    "#         if h_tmp == h_star:\n",
    "#             h_star_idx = i\n",
    "#         if h_tmp == h_bar:\n",
    "#             h_bar_idx = i\n",
    "#         obj_logprob, obj_prob = cal_prob_of_h(h_tmp, token_logprob)\n",
    "#         prob_list.append(obj_prob)\n",
    "\n",
    "#         d0_pairs = dlist_to_pairs(d0_str.split('\\n'))      \n",
    "#         corr_cnt,_ = count_corr_d0_pairs(d0_pairs, h_tmp)\n",
    "#         corr_list.append(corr_cnt)\n",
    "#         if all_possible_statuses[i][-1]=='on':\n",
    "#             screen_list.append(0)\n",
    "#         elif all_possible_statuses[i][-1]=='off':\n",
    "#             screen_list.append(1)\n",
    "#         else:\n",
    "#             screen_list.append(2)\n",
    "#     prob_list = np.array(prob_list)\n",
    "#     corr_list = np.array(corr_list)\n",
    "#     screen_list = np.array(screen_list)\n",
    "#     x_axis = np.arange(0,243)\n",
    "\n",
    "#     if color_type=='d0':\n",
    "#         ALPHA_LIST = [0.05, 0.2, 0.3, 0.45, 0.55, 0.7, 0.8, 0.9 , 1]#[0.05, 0.2, 0.3, 0.5, 1]\n",
    "#         for i in range(len(ALPHA_LIST)):\n",
    "#             mask = corr_list==i\n",
    "#             if i>0:\n",
    "#                 label = \"%d corr\"%i\n",
    "#             else:\n",
    "#                 label = None\n",
    "#             ax.bar(x_axis[mask],prob_list[mask],width=1, color='royalblue',alpha=ALPHA_LIST[i],label=label)\n",
    "#     elif color_type=='screen':\n",
    "#         COLOR_LIST = ['#f8ac8c', 'royalblue','#9e9e9e']#'#2878b5',\n",
    "#         LABELS = ['on', 'off', 'und']\n",
    "#         for i in range(len(COLOR_LIST)):\n",
    "#             mask = screen_list==i\n",
    "#             ax.bar(x_axis[mask],prob_list[mask],width=1, color=COLOR_LIST[i],alpha=0.7,label=LABELS[i])\n",
    "        \n",
    "#     if y_log:\n",
    "#         ax.set_yscale('log')\n",
    "#     ax.set_xlim(-3, 245)\n",
    "#     if ylim is not None:\n",
    "#         ax.set_ylim(ylim)\n",
    "#     if star:\n",
    "#         ax.plot((h_star_idx), (prob_list[h_star_idx]), color='red',alpha=1,linestyle=' ',marker='*',markersize=10, label=r'$h^*$')\n",
    "#         ax.plot((h_bar_idx), (prob_list[h_bar_idx]), color='red',alpha=1,linestyle=' ',marker='+',markersize=10, label=r'$\\hat{h}$')\n",
    "#     if legend:\n",
    "#         ax.legend(fontsize=16, ncol=5)\n",
    "#     if not x_tickle:\n",
    "#         ax.set_xticks([])\n",
    "#     if xlabel is not None:\n",
    "#         ax.set_xlabel(xlabel,fontsize=16)\n",
    "#     return prob_list, corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd54b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = 'E://P5_iICL//iterated_learning_exp//exp_logs//add_interaction//none_h006_alltorng_seed10086//prob_list_all.json'\n",
    "# save_path2 = 'E://P5_iICL//iterated_learning_exp//exp_logs//add_interaction//none_h006_alltorng_seed10086//other_results_all.json'\n",
    "# prob_list_read = json.load( open( save_path ))\n",
    "# results_read = json.load(open(save_path2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_star = results_read['rules'][0]\n",
    "# d0_str = results_read['d_sampled'][0]\n",
    "# all_possible_statuses = generate_all_statuses(N=len(OBJECTS), M=len(STATES), packed=False) # Control the fashion of h-243\n",
    "# fig, ax = plt.subplots(6,1,figsize=(15,35))\n",
    "# for i in range(GEN):\n",
    "#     if i>0:\n",
    "#         legend=False\n",
    "#     else:\n",
    "#         legend=True\n",
    "#     prob_list, corr_list = draw_pic(prob_list_read[i],h_star,d0_str, ax[i], True, ylim=[1e-15,1],legend=legend, color_type='screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27b114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1392c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
