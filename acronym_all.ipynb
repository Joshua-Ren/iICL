{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb60abab",
   "metadata": {},
   "source": [
    "# Acronym experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1005108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import permutations\n",
    "import os\n",
    "import openai\n",
    "from utils.gpt_api import multi_turn_chatgpt\n",
    "from utils.text_logger import text_logger\n",
    "from utils.acronym_utils import *\n",
    "\n",
    "M = 20\n",
    "M_easy = 10 # [2, 4, 6, 8, 10]\n",
    "SEED = 1314 # [10086, 42, 14843, 1314]\n",
    "BIAS_TYPE = \"easy\"  # [easy, easylong, easyshort, hard, random, imitation]\n",
    "M_hard = M - M_easy\n",
    "GLOBAL_TMP = 1\n",
    "GEN = 6\n",
    "LOOK_BACK = 0\n",
    "INPUT_FIRST = False\n",
    "UPPER = True\n",
    "MODEL_NAME =  \"claude-3-haiku-20240307\"  \n",
    "MODEL_NAME2 = \"claude-3-haiku-20240307\"\n",
    "# [\"gpt-3.5-turbo-0125\", \"gpt-4-0125-preview\"]\n",
    "# [\"claude-3-haiku-20240307\", \"claude-3-sonnet-20240229\", \"claude-instant-1.2\"]\n",
    "# [\"mistral-tiny-2312\", \"mistral-small-2312\"]\n",
    "\n",
    "EXP_NAME = \"inputfirst%s_upper%s_M%s_easy%d_G%s_seed%s\"%(str(INPUT_FIRST)[0],str(UPPER)[0],M,M_easy, GEN, SEED)\n",
    "EXP_PATH = './exp_logs_' + MODEL_NAME + '/acronym/'+BIAS_TYPE\n",
    "exp_path = os.path.join(EXP_PATH, EXP_NAME)\n",
    "\n",
    "LOG = text_logger(file_name='chat_log', exp_path=exp_path, silence = True)\n",
    "LOG.write_to_file('This is an experiment trying to see how generated data evolves')\n",
    "LOG.write_to_file('In this experiment, M is %d, G is %d, input first is %s, upper is %s. Global temperature is %f\\n'%(M, GEN, str(INPUT_FIRST), str(UPPER), GLOBAL_TMP))\n",
    "\n",
    "def rnd_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed) \n",
    "rnd_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ab0cc",
   "metadata": {},
   "source": [
    "## 0.Prepare the data $d^0$\n",
    "\n",
    "- Where the d0 comes from:\n",
    "  We select half from easy setting (\"acronym1_11.txt\") and half from hard setting (\"acronym1_51.txt\"). Make sure the output words in the easy setting are in COCA-top60k, while those in the hard setting are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94549e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SUP_PATH = 'acronym_supports'\n",
    "# COCA60K = pd.read_csv(os.path.join(SUP_PATH,'COCA 60000.csv'), encoding='ISO-8859-1')\n",
    "# easy_d0set = pd.read_csv(os.path.join(SUP_PATH,'easy.csv'))\n",
    "# hard_d0set = pd.read_csv(os.path.join(SUP_PATH,'hard.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a41c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_manager():\n",
    "    def __init__(self, sup_path='acronym_supports', input_first=False, upper=False):\n",
    "        self.sup_path = sup_path\n",
    "        self.COCA60K = pd.read_csv(os.path.join(self.sup_path,'COCA 60000.csv'), encoding='ISO-8859-1')\n",
    "        self.easy_d0set = pd.read_csv(os.path.join(self.sup_path,'easy.csv'))\n",
    "        self.hard_d0set = pd.read_csv(os.path.join(self.sup_path,'hard.csv'))\n",
    "        self.data_pool = pd.DataFrame(columns=['Output_upper','Output_lower','Input','RANK','TOTAL','generation'])\n",
    "        self.input_first = input_first\n",
    "        self.upper = upper\n",
    "\n",
    "    def word_ranking_total(self, word):\n",
    "        tgt_row = self.COCA60K[self.COCA60K['WORD']==word.lower()]\n",
    "        if len(tgt_row)>0:\n",
    "            tgt_rank, tgt_total = tgt_row['RANK'].iloc[0], tgt_row['TOTAL'].iloc[0]\n",
    "        else:\n",
    "            #tgt_rank, tgt_total = -1, 0\n",
    "            tgt_rank, tgt_total = 60001, 0\n",
    "        return tgt_rank, tgt_total\n",
    "        \n",
    "    def generate_d0(self, M_easy, M_hard, shuffle=True):\n",
    "        self.data_pool = pd.DataFrame(columns=['Output_upper','Output_lower','Input','RANK','TOTAL','generation'])\n",
    "        d0_easy = self.easy_d0set.sample(n=M_easy)\n",
    "        d0_hard = self.hard_d0set.sample(n=M_hard)\n",
    "        d0 = pd.concat([d0_easy,d0_hard]).sample(frac=1)\n",
    "        d0 = d0.drop(labels='Unnamed: 0',axis=1)\n",
    "        d0.insert(d0.shape[1],\"generation\",0)\n",
    "        self.data_pool = pd.concat([self.data_pool,d0])\n",
    "        return d0\n",
    "    \n",
    "    def get_data_json(self, data_pd):\n",
    "        fb_json = \"\"\n",
    "        for _, row in data_pd.iterrows():\n",
    "            out = row['Output_upper'] if self.upper else row['Output_lower']\n",
    "            inp = row['Input']\n",
    "            if self.input_first:\n",
    "                fb_json +=  '{\"Input\": \"%s\", \"Output\": \"%s\"}\\n'%(inp, out)\n",
    "            else:\n",
    "                fb_json += '{\"Output\": \"%s\", \"Input\": \"%s\"}\\n'%(out, inp)\n",
    "        return fb_json\n",
    "        \n",
    "    def get_data_str(self, data_pd):\n",
    "        fb_str = \"\"\n",
    "        for _, row in data_pd.iterrows():\n",
    "            out = row['Output_upper'] if self.upper else row['Output_lower']\n",
    "            inp = row['Input']\n",
    "            if self.input_first:\n",
    "                fb_str += \"Input: %s\\nOutput: %s\\n\\n\"%(inp, out)\n",
    "            else:\n",
    "                fb_str += \"Output: %s\\nInput: %s\\n\\n\"%(out, inp)\n",
    "        return fb_str\n",
    "    \n",
    "    def json_to_df(self, json_words, gen):\n",
    "        fb_dict = {'Output_upper':[],'Output_lower':[],'Input':[],'RANK':[],'TOTAL':[],'generation':[]}\n",
    "        fb_json = json.loads(json_words)\n",
    "        if 'Output' in fb_json.keys():\n",
    "            out_key = \"Output\"\n",
    "            inp_key = \"Input\"\n",
    "        else:\n",
    "            out_key = \"output\"\n",
    "            inp_key = \"input\"            \n",
    "        fb_dict['Output_upper'] = fb_json[out_key].upper()\n",
    "        fb_dict['Output_lower'] = fb_json[out_key].lower()\n",
    "        fb_dict['Input'] = fb_json[inp_key]\n",
    "        rank, total = DATA.word_ranking_total(fb_json['Output'].lower())\n",
    "        fb_dict['RANK'] = rank\n",
    "        fb_dict['TOTAL'] = total\n",
    "        fb_dict['generation'] = gen\n",
    "        fb_df = pd.DataFrame([fb_dict])\n",
    "        return fb_df\n",
    "    \n",
    "    def add_to_data_pool(self, json_words, gen=0):\n",
    "        df = self.json_to_df(json_words, gen)\n",
    "        self.data_pool = pd.concat([self.data_pool,df])\n",
    "        \n",
    "    def pool_reset_to_d0(self):\n",
    "        self.data_pool = self.data_pool.drop(self.data_pool[self.data_pool['generation']!=0].index)\n",
    "\n",
    "    def get_biased_df(self, bias_type, OUT_M):\n",
    "        if bias_type=='easy':\n",
    "            return self.data_pool.sort_values(by='RANK', ascending=True)[:OUT_M]\n",
    "        elif bias_type=='hard':\n",
    "            return self.data_pool.sort_values(by='RANK', ascending=False)[:OUT_M]\n",
    "        elif bias_type=='easyshort':\n",
    "            mask = self.data_pool['RANK']!=60001\n",
    "            return self.data_pool[mask].sort_values(by='TOTAL', ascending=True)[:OUT_M]\n",
    "        elif bias_type=='easylong':\n",
    "            mask = self.data_pool['RANK']!=60001\n",
    "            return self.data_pool[mask].sort_values(by='TOTAL', ascending=False)[:OUT_M]\n",
    "        elif bias_type=='random':\n",
    "            return self.data_pool.sample(n=OUT_M)\n",
    "    \n",
    "    def get_generation_df(self, gen=0):\n",
    "        return self.data_pool[self.data_pool['generation']==gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edebd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = data_manager(sup_path='E:\\\\P5_iICL\\\\iterated_learning_exp\\\\acronym_supports', input_first=INPUT_FIRST, upper=UPPER)\n",
    "d0 = DATA.generate_d0(M_easy=M_easy, M_hard=M_hard, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55b955",
   "metadata": {},
   "source": [
    "## 1. Iteratively generate new examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75c0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#persona = \"You are a pattern following assistant.\"\n",
    "if BIAS_TYPE == 'easylong':\n",
    "    persona = \"You favor long words.\" #\"You are a helpful assistant.\"#\n",
    "elif BIAS_TYPE == 'easyshort':\n",
    "    persona = \"You favor short words a lot.\" #\"You are a helpful assistant.\"#\n",
    "elif BIAS_TYPE == 'hard':\n",
    "    persona = \"You favor rare words.\" #\"You are a helpful assistant.\"#\n",
    "else:\n",
    "    persona = \"You favor common words.\" #\"You are a helpful assistant.\"#\n",
    "LOG.msg_to_gpt(persona)\n",
    "GPT_AGENT = multi_turn_chatgpt(model=MODEL_NAME, temperature=GLOBAL_TMP, top_p=1, logger=LOG, game_description=persona)\n",
    "GPT_AGENT2 = multi_turn_chatgpt(model=MODEL_NAME2, temperature=GLOBAL_TMP*0.5, top_p=1, logger=LOG, game_description=persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f66ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# side_instruction = \"the input comes first\"\n",
    "# json_format = \"- Input: str, the list of words\\n- Output: str, the acronym\"\n",
    "# d0_str = DATA.get_data_str(d0,upper=False, out_first=False)\n",
    "\n",
    "# def get_data_prompt(d_str, M, d_json):\n",
    "#     if d_json is not None:\n",
    "#         add = \"\\n%s\"%d_json\n",
    "#     else:\n",
    "#         add = \"\"\n",
    "#     if INPUT_FIRST:\n",
    "#         side_instruction = \"the input comes first\"\n",
    "#         json_format = '- Input: str, the list of words\\n- Output: str, the acronym.'%add        \n",
    "#     else:\n",
    "#         side_instruction = \"the output comes first\"\n",
    "#         json_format = '- Output: str, the acronym\\n- Input: str, the list of words.'%add\n",
    "    \n",
    "#     data_prompt = \"Here are some input-output pairs. The input is a list of words. The output is the concatenation of the first letter of each word in the input, i.e., its acronym. For example:\\n\\n%sPlease provide %d more examples following this pattern, where %s.\\nPlease ONLY return a JSON string with the following keys:\\n%s\"%(d_str, M, side_instruction, json_format)\n",
    "#     return data_prompt\n",
    "\n",
    "def get_data_prompt(d_str, M, d_json):\n",
    "    if INPUT_FIRST:\n",
    "        side_instruction = \"the input comes first\"\n",
    "        json_format = '- Input: str, the list of words\\n- Output: str, the acronym.'     \n",
    "    else:\n",
    "        side_instruction = \"the output comes first\"\n",
    "        json_format = '- Output: str, the acronym\\n- Input: str, the list of words.'\n",
    "    \n",
    "    data_prompt = \"Here are some input-output pairs. The input is a list of words. The output is the concatenation of the first letter of each word in the input, i.e., its acronym. For example:\\n\\n%sPlease provide %d different examples following this pattern, where %s.\\n%s\\nPlease return examples strictly following this format:\\n%s\"%(d_str, M, side_instruction, persona, d_json)\n",
    "    return data_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61854702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:56<00:00, 19.47s/it]\n"
     ]
    }
   ],
   "source": [
    "d0_str = DATA.get_data_str(d0)\n",
    "if INPUT_FIRST:\n",
    "    example_json = '{\"Input\": \"word1, word2, ...\", \"Output\": \"acronym\"}\\n{\"Input\": \"word1, word2, ...\", \"Output\": \"acronym\"}'\n",
    "else:\n",
    "    example_json = '{\"Output\": \"acronym\", \"Input\": \"word1, word2, ...\"}\\n{\"Output\": \"acronym\", \"Input\": \"word1, word2, ...\"}'\n",
    "#d0_json = DATA.get_data_json(d0[-2:])\n",
    "d0_json = example_json\n",
    "d0_prompt = get_data_prompt(d0_str, M,d_json=d0_json)\n",
    "dg_prompt = d0_prompt\n",
    "for g in tqdm(range(GEN)):\n",
    "    LOG.write_to_file('----------- Gen %d -----------'%g)\n",
    "    if g%2==0:\n",
    "        hd_feedback, _, cnt_tokens = GPT_AGENT.call_chatgpt(dg_prompt, fake_response=None, \n",
    "                                                  logprobs=False, top_logprobs=None, lookback_round=LOOK_BACK)\n",
    "    else:\n",
    "        hd_feedback, _, cnt_tokens = GPT_AGENT2.call_chatgpt(dg_prompt, fake_response=None, \n",
    "                                                  logprobs=False, top_logprobs=None, lookback_round=LOOK_BACK)        \n",
    "    # ------ Put the generated data into data.pool\n",
    "    #fb_list = hd_feedback.split('\\n')\n",
    "    fb_list = get_fblist_from_hdfeedback(hd_feedback)\n",
    "    for i in range(len(fb_list)):\n",
    "        if len(fb_list[i].strip())>0:\n",
    "            DATA.add_to_data_pool(fb_list[i].strip(), gen=g+1)\n",
    "\n",
    "    # ------------ Filter on dt\n",
    "    if BIAS_TYPE==\"imitation\":\n",
    "        dg = DATA.get_generation_df(gen=g+1)\n",
    "    else:\n",
    "        dg = DATA.get_biased_df(bias_type=BIAS_TYPE, OUT_M=M) \n",
    "    \n",
    "    # ------- Get the data generated by this generation\n",
    "    dg_str = DATA.get_data_str(dg)\n",
    "    #dg_json = DATA.get_data_json(dg[-2:])\n",
    "    dg_json = example_json\n",
    "    dg_prompt = get_data_prompt(dg_str, M, dg_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c5eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.data_pool.to_csv(os.path.join(exp_path,'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5fe77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool = DATA.data_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203d782-bcf1-46d6-8507-23e6b9b7b14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aec35c7",
   "metadata": {},
   "source": [
    "## 2. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d352fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Calculate the length of acronyms\n",
    "def cal_acro_length_df(df_slice):\n",
    "    cnt_num, cnt_str = 0, 0\n",
    "    for _, row in df_slice.iterrows():\n",
    "        cnt_num += 1\n",
    "        cnt_str += len(row['Output_upper'])\n",
    "    return np.sum(cnt_str)/np.sum(cnt_num)\n",
    "\n",
    "# ------ Plot ratio all-data\n",
    "def _get_rank_mean(rnk_list):\n",
    "    rank_cnt = 0\n",
    "    for i in range(len(rnk_list)):\n",
    "        if rnk_list[i] == -1:\n",
    "            rank_cnt += 60000\n",
    "        else:\n",
    "            rank_cnt += rnk_list[i]\n",
    "    return rank_cnt/len(rnk_list)\n",
    "\n",
    "def get_ratio_and_rank(data_pool, old_results=False):\n",
    "    ratio_list, ratioall_list, avgrank_list,easyrank_list = [], [], [], []\n",
    "    avglen_list = []\n",
    "    all_easy, all_hard = 0, 0\n",
    "    for g in range(GEN+1):\n",
    "        if old_results:\n",
    "            mask_hard = data_pool[data_pool['generation']==g]['RANK']==-1\n",
    "            mask_easy = data_pool[data_pool['generation']==g]['RANK']>0\n",
    "        else:\n",
    "            mask_hard = data_pool[data_pool['generation']==g]['RANK']==60001\n",
    "            mask_easy = data_pool[data_pool['generation']==g]['RANK']<60001\n",
    "        mask_gen = data_pool['generation']==g\n",
    "        avg_len = cal_acro_length_df(data_pool[mask_gen])\n",
    "        cnt_easy, cnt_hard = mask_easy.sum(), mask_hard.sum()\n",
    "        all_easy += cnt_easy\n",
    "        all_hard += cnt_hard\n",
    "        ratio_list.append(cnt_easy / (cnt_easy+cnt_hard))\n",
    "        ratioall_list.append(all_easy / (all_easy+all_hard))\n",
    "        avgrank = _get_rank_mean(list(data_pool[data_pool['generation']==g]['RANK']))\n",
    "        easyrank = data_pool[data_pool['generation']==g][mask_easy]['RANK'].mean()\n",
    "        avgrank_list.append(avgrank)\n",
    "        easyrank_list.append(easyrank)\n",
    "        avglen_list.append(avg_len)\n",
    "    return ratio_list, ratioall_list, avgrank_list, easyrank_list, avglen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4,figsize=(20,4))\n",
    "# ------ Plot ratio per-gen\n",
    "ratio_list, ratioall_list, avgrank_list, easyrank_list, avglen_list = get_ratio_and_rank(data_pool)\n",
    "ax[0].plot(ratio_list)\n",
    "ax[1].plot(ratioall_list)\n",
    "ax[2].plot(avgrank_list)\n",
    "ax[3].plot(avglen_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb3030",
   "metadata": {},
   "source": [
    "## 3. Genearate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "Ms = [2,4,6,8,10]#[10, 8, 6, 4, 2]#\n",
    "Seeds = [10086, 42, 14843, 1314]\n",
    "COLORS = [\"#2878B5\", \"#8983bf\", \"#B1CE46\",\"orange\" , \"#D76364\"]#\"#F1D77E\"\n",
    "#COLORS = [cm.tab20c.colors[0], cm.tab20c.colors[1], cm.tab20c.colors[3], cm.tab20c.colors[7],cm.tab20c.colors[4]]\n",
    "#COLORS = [\"#F27970\", \"#BB9727\", \"#54B345\", \"#05B9E2\", \"#C76DA2\"]\n",
    "#COLORS = [\"blue\", \"red\", \"green\", \"yellow\", \"cyan\", \"black\",\"#63E398\"]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,5))\n",
    "x_axis = np.arange(0, 6)\n",
    "for j in range(len(Ms)):\n",
    "    m = Ms[j]\n",
    "    ratio_np = np.zeros((len(Seeds),6))\n",
    "    ratioall_np = np.zeros((len(Seeds),6))\n",
    "    avgrank_np = np.zeros((len(Seeds),6))\n",
    "    easyrank_np = np.zeros((len(Seeds),6))\n",
    "    for i in range(len(Seeds)):\n",
    "        exp_name = \"inputfirstF_upperT_M20_easy%d_G6_seed%d\"%(m, Seeds[i])\n",
    "        #exp_name = \"inputfirstF_upperF_M20_easy%d_G6_seed%d\"%(m, Seeds[i])\n",
    "        main_path = \"./exp_logs_gpt-3.5-turbo-0125/acronym/easy\"\n",
    "        #main_path = \"./exp_logs_claude-3-haiku-20240307/acronym/imitation\"\n",
    "        \n",
    "        data_pool = pd.read_csv(os.path.join(main_path, exp_name,'data.csv'))\n",
    "        ratio_list, ratioall_list, avgrank_list, easyrank_list = get_ratio_and_rank(data_pool)\n",
    "        ratio_np[i,:], ratioall_np[i,:], avgrank_np[i,:], easyrank_np[i,:] = ratio_list, ratioall_list, avgrank_list, easyrank_list\n",
    "        \n",
    "    ax[0].plot(x_axis, ratio_np.mean(0), color=COLORS[j],linewidth=2, marker='+', markersize=15, label='$N_e$ %d'%m,)\n",
    "    ax[0].fill_between(x_axis, ratio_np.mean(0)-ratio_np.var(0), ratio_np.mean(0)+ratio_np.var(0), alpha=0.1, color=COLORS[j])\n",
    "    ax[1].plot(x_axis, avgrank_np.mean(0), color=COLORS[j],linewidth=2, marker='+', markersize=15)\n",
    "    ax[1].fill_between(x_axis, avgrank_np.mean(0)-0.5*avgrank_np.std(0), avgrank_np.mean(0)+0.5*avgrank_np.std(0), alpha=0.1, color=COLORS[j])\n",
    "ax[0].legend(fontsize=14)\n",
    "ax[0].set_xlabel(\"Generation\",fontsize=16)\n",
    "ax[0].set_ylabel(\"Ratio of easy samples\",fontsize=16)\n",
    "ax[0].grid()\n",
    "ax[1].set_xlabel(\"Generation\",fontsize=16)\n",
    "ax[1].set_ylabel(\"Average rank of $d^t$\",fontsize=16)\n",
    "ax[1].set_yticklabels([\"0\",\"0k\", \"10k\", \"20k\", \"30k\", \"40k\", \"50k\"])\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "Ms = [2,4,6,8,10]#[10, 8, 6, 4, 2]#\n",
    "Seeds = [10086, 42, 14843, 1314]\n",
    "COLORS = [\"#2878B5\", \"#8983bf\", \"#B1CE46\", \"#F1D77E\", \"#D76364\"]\n",
    "#COLORS = [cm.tab20c.colors[0], cm.tab20c.colors[1], cm.tab20c.colors[3], cm.tab20c.colors[7],cm.tab20c.colors[4]]\n",
    "#COLORS = [\"#F27970\", \"#BB9727\", \"#54B345\", \"#05B9E2\", \"#C76DA2\"]\n",
    "#COLORS = [\"blue\", \"red\", \"green\", \"yellow\", \"cyan\", \"black\",\"#63E398\"]\n",
    "fig, ax = plt.subplots(1,4,figsize=(20,4))\n",
    "x_axis = np.arange(0, 6)\n",
    "for j in range(len(Ms)):\n",
    "    m = Ms[j]\n",
    "    ratio_np = np.zeros((len(Seeds),6))\n",
    "    ratioall_np = np.zeros((len(Seeds),6))\n",
    "    avgrank_np = np.zeros((len(Seeds),6))\n",
    "    easyrank_np = np.zeros((len(Seeds),6))\n",
    "    for i in range(len(Seeds)):\n",
    "        exp_name = \"inputfirstF_upperT_M20_easy%d_G6_seed%d\"%(m, Seeds[i])\n",
    "        main_path = \"./exp_logs_acronym\"\n",
    "        data_pool = pd.read_csv(os.path.join(main_path, exp_name,'data.csv'))\n",
    "        ratio_list, ratioall_list, avgrank_list, easyrank_list = get_ratio_and_rank(data_pool)\n",
    "        ratio_np[i,:], ratioall_np[i,:], avgrank_np[i,:], easyrank_np[i,:] = ratio_list, ratioall_list, avgrank_list, easyrank_list\n",
    "        \n",
    "    ax[0].plot(x_axis, ratioall_np.mean(0), label='%d easy in d0'%m, color=COLORS[j])\n",
    "    ax[0].fill_between(x_axis, ratioall_np.mean(0)-ratioall_np.var(0), ratioall_np.mean(0)+ratioall_np.var(0), alpha=0.15, color=COLORS[j])\n",
    "    ax[1].plot(x_axis, ratio_np.mean(0), color=COLORS[j])\n",
    "    ax[1].fill_between(x_axis, ratio_np.mean(0)-ratio_np.var(0), ratio_np.mean(0)+ratio_np.var(0), alpha=0.15, color=COLORS[j])\n",
    "    ax[2].plot(x_axis, avgrank_np.mean(0), color=COLORS[j])\n",
    "    ax[2].fill_between(x_axis, avgrank_np.mean(0)-0.5*avgrank_np.std(0), avgrank_np.mean(0)+0.5*avgrank_np.std(0), alpha=0.15, color=COLORS[j])\n",
    "    ax[3].plot(x_axis, easyrank_np.mean(0), color=COLORS[j])\n",
    "    ax[3].fill_between(x_axis, easyrank_np.mean(0)-0.5*easyrank_np.std(0), easyrank_np.mean(0)+0.5*easyrank_np.std(0), alpha=0.15, color=COLORS[j])\n",
    "ax[0].legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6e5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36b150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bcbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10201e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5fd0013",
   "metadata": {},
   "source": [
    "### Backup code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
